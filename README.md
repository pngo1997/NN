# 🧠 Neural Network Backpropagation & Optimization  

## 📜 Overview  
This project explores key concepts in **Neural Network Training**, including:  
1. **Forward Propagation in Neural Networks**  
2. **Alternative Syntax Optimization**  
3. **Backpropagation Code Explanation**  
4. **Derivation for Cross-Entropy Cost Function Optimization**  

📌 **Programming Language**: `Python 3`  
📌 **Frameworks Used**: `NumPy`, `Jupyter Notebook`  

## 🚀 1️⃣ Forward Propagation in Neural Networks   
Analyze and compare **two implementations of forward propagation**:  
- `feedforward()` – Used for evaluation/testing.  
- `backprop()` – Performs forward propagation as part of backpropagation.  

## 🛠 2️⃣ Alternative Syntax for Mini-Batch Creation  
Optimize the mini-batch creation syntax from `SGD()` function.

## 🔢 3️⃣ Derivation of Cross-Entropy Cost Function 
Compare Quadratic vs. Cross-Entropy Cost Functions and derive why bias terms vanish in optimization.
